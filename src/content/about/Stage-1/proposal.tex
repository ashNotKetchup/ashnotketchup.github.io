\documentclass[../main.tex]{subfiles}
% \documentclass[]{article}
\usepackage{biblatex} %Imports biblatex package
\addbibresource{references.bib} %Import the bibliography file
\begin{document}

% two inter-actors "have to coordinate both the content and process of what they are doing...they need to update their common ground moment by moment" \cite{clark_grounding_1991}. 

\section{My PhD}
Artificial Intelligence (AI) is increasingly applied in creative fields for the solution of problems (complex mappings in NIMEs, sonification in interfaces) as well as the creation of artefacts (generate new musical ideas, re-arrange existing material). However, the tools used for training and implementation of such AI systems are often predicated on universalist design principles and large, pre-trained models, alienating end-users from their own data and its utility. For developers, this is primarily due to a poor understanding of the typical workflows of end users. Similarly, users face barriers due to generally low machine learning literacy, as well as a lack of model parameters/explanations exposed to them. This paradigm magnifies global inequalities in the digital sphere. 

I am examining the use-case of user-defined latent spaces for audio-driven music generation. I consider sample-based music composition not only as the domain to be technically supported, but as a prototypical example of potential interaction with musical AI systems.
% aiming to implement an XAI and EUP intervention which makes the process more equitable. 
It is proposed that this is achieved through a combination of explainable and interactive (as well as interactive explanation and explainable interaction). This will be evaluated and iterated upon through the participatory design and evaluation of tools for sample-based music making. I intend to look at whether a shift in how we design, evaluate, and implement interactive musical XAI systems can result in richer, more meaningful interaction for computer musicians across a range of sample-based practices. 
% Here, I outline the trajectory of my PhD, which will investigate how participatory design processes might result in tools which are more readily modified/customised by users.

% \end{abstract}
\section{So far...}
\subsection{Modules}
Exploring the topics of the above project, during my first-year classes I:
- Made a physical interface for programming euclidean rhythms in real-time
- Trained a large language model on scraped data to describe synth patches
- Made an active learning model which classifies musical emotion in a semi-supervised fashion
- Designed a number of studies for evaluating human interactions in tech-mediated situations

\subsection{Research}
As well as modules, I also undertook a number of research tasks in anticipation of my stage 0 review. These included:
- A literature review of explainable AI methods, and their evaluation, largely informed by \cite{bryan-kinns_exploring_2021} and \cite{a.SystematicReviewExplainable2023}
- Technical investigation into methods of explanation of symbolic music models models based on VAE and RNN architechtures, such as regularisation \cite{pati_attribute-based_2020} or interactive [wekinator] and small data approaches [r-vae]
- Autoethnographic exploration of these tools within the compositional practices of algorithmic composition and a punk band (separately, for the sake of anyone with hearing intact).

From these, I identified a lack of robust literature on creating and evaluating explanations in the context of music. A particular shortcoming in the analysis of \cite{bryan-kinns_exploring_2021} is the modelling of \textbf{grounding} without the reflexivity parameterised in \cite{clark_grounding_1991}, where it was originally defined. I ruled out a one-size-fits all approach to designing explanations. I also swore against symbolic models, due to their rooting in the homogenised landscape of western classical and art musics (a reflection of the datasets available, and people willing to collect or work on them) \cite{gioti_artificial_2021}.

I started working with rave \cite{caillon_rave_2021} and other generative neural audio systems. These systems use a neural network to learn a lower dimensional, latent space representing timbral fragments of a sound. Sound can then be generated by plotting paths through this space. There is lots of potential for the generation, modulation and retrieval of sounds using the latent spaces of these models, but they are currently not explainable, as the axes are learned in an unsuppervised fashion, and therefore differ between models. I replicated a study from Vigliensoni and Fiebrink \cite{vigliensoni_interacting_2023} which introduced the interactive machine learning paradigm to the latent space (users can explore the latent space and then create mappings to lower dimensional controls to interpolate between places in it which are interesting). However, this has two shortcomings: 1 - the initial navigation of the latent space is made no more explainable by this method, since the meaning of the axes is still not communicated
2 - The learned mapping is not transferable, since each model differs drastically.

\subsection{Questions}
The questions I have right now are:
- What do explanations look like if we distinguish less between sound and music? 
- In interactive machine learning paradigms, the roles of explanation, analysis and generation remain largely fixed. How do explanations impact interactivity in machine learning? Can explanations be altered interactively? Can we build low-fidelity personalised explanations? Conversely, can explanations crowd-sourced?
% What can a user do once they have an explanation? How can a user or group of users change an explanation? 
- How does mono-modal and multimodal context impact explanations? Haptics?
- Why explain? Do explanations 'improve' the user's experience? How do we measure that?

\section{Onwards}

\subsection{Current Designs - Interacting with neural sound}
- I am currently designing a system for manipulating the latent representation of pre-loaded sounds [add image from pitch deck] (This is currently on pause while i work on the bellow)
- I am also designing a system which facilitates user-editable generation-explanation pairs. This system will load a chosen generative model, then use a chosen classifier to map between semantic descriptors and the axes most relevant to them. Currently I am exploring methods of multivariate analysis, but am unsure how to evaluate/compare the systems.

\subsection{Future Work}
- I aim to complete a systematic literature review of explanation mechanisms/paradigms in audio/signal processing, in collaboration with ....
- Having just received approval from the department, I am also recruiting for an interview study trying to understand the ways in which sample-based composers understand the process of sampling. Interesting collaborations with musicians in Nairobi and the `etudes for live electronics' project in Austria have already revealed some interesting patterns, such as the parallels between sample collection and data-set management. Can we design with these existing processes in mind?
- Once my technical exploration is done, I want to implement and evaluate these systems with workshops and participatory design. I am currently thinking hard about how to do this, so am very open to suggestions from the community!
- I am also keen to bring a more critical angle to this work. Though, I am confident this will emerge over the duration of the PhD.

\printbibliography

\end{document}

